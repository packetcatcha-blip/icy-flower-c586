{
  "continue.telemetryEnabled": false,
  "continue.defaultModel": "llama3", // Or your LM Studio model
  "continue.models": [
    {
      "model": "llama3",
      "provider": "ollama",
      "apiBase": "http://localhost:11434"
    }
  ]
}